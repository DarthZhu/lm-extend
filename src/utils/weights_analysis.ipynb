{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import umap # Requires: pip install umap-learn\n",
    "\n",
    "from safetensors import safe_open\n",
    "# from transformers import AutoConfig, AutoModelForCausalLM, AutoTokenizer, LlavaForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a503e118",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_MODEL_DIRECTORY=\"data/local_llms\"\n",
    "\n",
    "def load_index(model_name):\n",
    "    model_directory = os.path.join(ROOT_MODEL_DIRECTORY, model_name)\n",
    "    # check is bin file or is safetensors file\n",
    "    if \"model.safetensors.index.json\" in os.listdir(model_directory):\n",
    "        with open(os.path.join(model_directory, \"model.safetensors.index.json\")) as f:\n",
    "            index = json.load(f)\n",
    "    elif \"pytorch_model.bin.index.json\" in os.listdir(model_directory):\n",
    "        with open(os.path.join(model_directory, \"pytorch_model.bin.index.json\")) as f:\n",
    "            index = json.load(f)\n",
    "    return index\n",
    "\n",
    "def load_tensors(model_name, load_weight_names=None):\n",
    "    model_directory = os.path.join(ROOT_MODEL_DIRECTORY, model_name)\n",
    "    # check is bin file or is safetensors file\n",
    "    if \"model.safetensors.index.json\" in os.listdir(model_directory):\n",
    "        with open(os.path.join(model_directory, \"model.safetensors.index.json\")) as f:\n",
    "            index = json.load(f)\n",
    "        \n",
    "        # process map file\n",
    "        tensor_file_map = index.get(\"weight_map\")\n",
    "        if tensor_file_map is None:\n",
    "            raise AssertionError(\"Safetensors index file has no weight map.\")\n",
    "            \n",
    "        # load necessary weights if specified\n",
    "        if load_weight_names:\n",
    "            # find required files\n",
    "            required_files = []\n",
    "            for name in load_weight_names:\n",
    "                # only add \"language model\" when loading from multimodal model\n",
    "                if name not in tensor_file_map.keys():\n",
    "                    name = \"language_model.\" + name\n",
    "                if name not in tensor_file_map.keys():\n",
    "                    # raise AssertionError(f\"{name} not found in {model_name}.\")\n",
    "                    replaced_name = name.replace(\"language_model.\", \"\")\n",
    "                    print(f\"{replaced_name} not found in {model_name}.\")\n",
    "                    continue\n",
    "                required_files.append(tensor_file_map[name])\n",
    "            required_files = list(set(required_files))\n",
    "                \n",
    "            # open required files\n",
    "            weight_map = {}\n",
    "            for file in required_files:\n",
    "                with safe_open(os.path.join(model_directory, file), framework=\"pt\") as f:\n",
    "                    for k in f.keys():\n",
    "                        if k in load_weight_names:\n",
    "                            weight_map[k] = f.get_tensor(k)\n",
    "                        else:\n",
    "                            k_ = k.replace(\"language_model.\", \"\")\n",
    "                            if k_ in load_weight_names:\n",
    "                                weight_map[k_] = f.get_tensor(k)\n",
    "                            \n",
    "        # load all tensors\n",
    "        else:\n",
    "            all_files = []\n",
    "            for k in tensor_file_map.keys():\n",
    "                all_files.append(tensor_file_map[k])\n",
    "            all_files = list(set(all_files))\n",
    "            \n",
    "            # open files\n",
    "            weight_map = {}\n",
    "            for file in all_files:\n",
    "                with safe_open(os.path.join(model_directory, file), framework=\"pt\") as f:\n",
    "                    for k in f.keys():\n",
    "                        if k in load_weight_names:\n",
    "                            weight_map[k] = f.get_tensor(k)\n",
    "        return weight_map\n",
    "    \n",
    "    elif \"pytorch_model.bin.index.json\" in os.listdir(model_directory):\n",
    "        with open(os.path.join(model_directory, \"pytorch_model.bin.index.json\")) as f:\n",
    "            index = json.load(f)\n",
    "        \n",
    "        # process map file\n",
    "        tensor_file_map = index.get(\"weight_map\")\n",
    "        if tensor_file_map is None:\n",
    "            raise AssertionError(\"Safetensors index file has no weight map.\")\n",
    "            \n",
    "        # load necessary weights if specified\n",
    "        if load_weight_names:\n",
    "            # find required files\n",
    "            required_files = []\n",
    "            for name in load_weight_names:\n",
    "                if name not in tensor_file_map.keys():\n",
    "                    name = \"language_model.\" + name\n",
    "                if name not in tensor_file_map.keys():\n",
    "                    # raise AssertionError(f\"{name} not found in {model_name}.\")\n",
    "                    print(f\"{name} not found in {model_name}.\")\n",
    "                    continue\n",
    "                required_files.append(tensor_file_map[name])\n",
    "            required_files = list(set(required_files))\n",
    "                \n",
    "            # open required files\n",
    "            weight_map = {}\n",
    "            for file in required_files:\n",
    "                f = torch.load(os.path.join(model_directory, file))\n",
    "                for k in f.keys():\n",
    "                    if k in load_weight_names:\n",
    "                        weight_map[k] = f.get_tensor(k)\n",
    "                    else:\n",
    "                        k_ = k.replace(\"load_weight_names\", \"\")\n",
    "                        if k_ in load_weight_names:\n",
    "                            weight_map[k_] = f.get_tensor(k)\n",
    "        # load all tensors\n",
    "        else:\n",
    "            all_files = []\n",
    "            for k in tensor_file_map.keys():\n",
    "                all_files.append(tensor_file_map[k])\n",
    "            all_files = list(set(all_files))\n",
    "            \n",
    "            # open files\n",
    "            weight_map = {}\n",
    "            for file in all_files:\n",
    "                f = torch.load(os.path.join(model_directory, file))\n",
    "                for k in f.keys():\n",
    "                    if k in load_weight_names:\n",
    "                        weight_map[k] = f.get_tensor(k)\n",
    "        return weight_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807b9130",
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_model = \"Qwen2-merged-weighted-all\"\n",
    "# models = [\n",
    "#     \"ft-text\",\n",
    "#     \"ft-image\",\n",
    "#     \"ft-video\",\n",
    "#     \"ft-mm\"\n",
    "# ]\n",
    "\n",
    "base_model = \"Qwen2-merged-weighted-all\"\n",
    "models = [\n",
    "    \"Qwen2-7B-Instruct\",\n",
    "    \"Qwen2-VL-7B-Instruct\",\n",
    "    \"LLaVA-Video-7B-Qwen2\",\n",
    "    \"llava-onevision-qwen2-7b-si\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78beb1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weights\n",
    "model_index = load_index(base_model)\n",
    "base_weights = load_tensors(base_model, model_index[\"weight_map\"].keys())\n",
    "\n",
    "expert_models = {}\n",
    "\n",
    "for model in models:\n",
    "    expert_weights = load_tensors(model, model_index[\"weight_map\"].keys())\n",
    "    expert_models[model] = expert_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26048357",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_fn(shift_tensor):\n",
    "    return np.linalg.norm(shift_tensor)\n",
    "    # Other options:\n",
    "    # return np.mean(np.abs(shift_tensor))\n",
    "    # return np.var(shift_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791d50c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_names = list(base_weights.keys())\n",
    "aggregated_shifts_list = []\n",
    "model_order = []\n",
    "for name, expert_w in expert_models.items():\n",
    "    model_order.append(name)\n",
    "    model_agg_vector = []\n",
    "    for layer_name in layer_names:\n",
    "        if layer_name in expert_w and layer_name in base_weights:\n",
    "            shift = expert_w[layer_name] - base_weights[layer_name]\n",
    "            agg_value = aggregate_fn(shift)\n",
    "            model_agg_vector.append(agg_value)\n",
    "        else:\n",
    "            model_agg_vector.append(0) # Or handle missing layers appropriately\n",
    "\n",
    "    aggregated_shifts_list.append(model_agg_vector)\n",
    "    \n",
    "aggregated_shifts_list.append([0] * len(layer_names)) # Add base model as zero vector\n",
    "model_order.append(base_model)\n",
    "\n",
    "stacked_agg_shifts = np.array(aggregated_shifts_list)\n",
    "\n",
    "print(f\"Stacked aggregated shifts into array of shape: {stacked_agg_shifts.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ce1715",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4. Optional: Scale the Data ---\n",
    "# Scaling is often recommended before PCA and can help t-SNE/UMAP.\n",
    "# scaler = StandardScaler()\n",
    "# scaled_shifts = scaler.fit_transform(stacked_shifts)\n",
    "# print(\"Applied StandardScaler to the shift vectors.\")\n",
    "\n",
    "# Choose which data to use for reduction:\n",
    "# data_for_reduction = scaled_shifts # Use scaled data\n",
    "# data_for_reduction = stacked_shifts # Or use unscaled data\n",
    "data_for_reduction = stacked_agg_shifts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4cdf9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 3 # Reduce to 2 dimensions for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72972621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # PCA\n",
    "# pca = PCA(n_components=n_components)\n",
    "# pca_result = pca.fit_transform(data_for_reduction)\n",
    "# print(f\"\\nPCA completed. Explained variance ratio: {pca.explained_variance_ratio_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dccbfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE\n",
    "# Note: t-SNE hyperparameters (perplexity, learning_rate, n_iter) can significantly affect results.\n",
    "# Adjust perplexity based on the number of points (models). A common range is 5-50.\n",
    "perplexity_value = min(30, len(model_order) - 1) # Ensure perplexity < n_samples\n",
    "tsne = TSNE(n_components=n_components, perplexity=perplexity_value, random_state=42, n_iter=1000)\n",
    "tsne_result = tsne.fit_transform(data_for_reduction)\n",
    "print(f\"t-SNE completed (perplexity={perplexity_value}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1946f0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # UMAP\n",
    "# # Note: UMAP hyperparameters (n_neighbors, min_dist) also affect results.\n",
    "# n_neighbors_value = min(15, max(2, len(model_order) - 1)) # Ensure n_neighbors < n_samples\n",
    "# umap_reducer = umap.UMAP(n_components=n_components, n_neighbors=n_neighbors_value, min_dist=0.1, random_state=42)\n",
    "# umap_result = umap_reducer.fit_transform(data_for_reduction)\n",
    "# print(f\"UMAP completed (n_neighbors={n_neighbors_value}).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd17af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # Import for 3D plotting\n",
    "import numpy as np # Assuming numpy is used for tsne_result\n",
    "\n",
    "fig = plt.figure(figsize=(18, 8)) # Adjusted figure size for 3D\n",
    "ax = fig.add_subplot(111, projection='3d') # Create a 3D subplot\n",
    "\n",
    "# plt.title('Fine-tuned Model Weight Shifts Relative to Base Model (3D)', fontsize=16)\n",
    "\n",
    "result = tsne_result  # Use the result you want to plot (should have 3 components)\n",
    "\n",
    "# Check if the result has at least 3 components\n",
    "if result.shape[1] < 3:\n",
    "    raise ValueError(\"The 'result' data must have at least 3 components for a 3D plot.\")\n",
    "\n",
    "# Scatter plot - using the 3D axes\n",
    "# Using result[:, 0], result[:, 1], and result[:, 2] for x, y, z coordinates\n",
    "ax.scatter(result[:, 0], result[:, 1], result[:, 2], s=100, alpha=0.8, label='Expert Models')\n",
    "\n",
    "# Set axis labels\n",
    "# ax.set_xlabel(\"Component 1\")\n",
    "# ax.set_ylabel(\"Component 2\")\n",
    "# ax.set_zlabel(\"Component 3\") # Add Z-axis label\n",
    "\n",
    "# Add grid (already part of 3D plots by default, but can customize)\n",
    "ax.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# Add text labels to points in 3D\n",
    "# Need to get current axis limits to calculate offset if desired,\n",
    "# but direct offsetting might be simpler in 3D initially.\n",
    "# For simplicity, a small constant offset is used here.\n",
    "# You might need to adjust offsets based on your data range.\n",
    "x_offset_3d = 0.1 * (result[:, 0].max() - result[:, 0].min())\n",
    "y_offset_3d = 0.01 * (result[:, 1].max() - result[:, 1].min())\n",
    "z_offset_3d = 0.01 * (result[:, 2].max() - result[:, 2].min())\n",
    "\n",
    "\n",
    "for i, name in enumerate(model_order):\n",
    "    ax.text(result[i, 0] - x_offset_3d,\n",
    "            result[i, 1] + y_offset_3d,\n",
    "            result[i, 2] + z_offset_3d,\n",
    "            name,\n",
    "            fontsize=10)\n",
    "\n",
    "# Optional: Add a legend\n",
    "# ax.legend() # In 3D, legend placement might need adjustment\n",
    "\n",
    "# --- Adjust layout and save ---\n",
    "# plt.tight_layout() # tight_layout might have issues with 3D plots sometimes.\n",
    "                  # Manual adjustment of subplot parameters might be needed if overlapping.\n",
    "# ax.view_init(elev=0., azim=-30) # Try different elevation and azimuth angles\n",
    "\n",
    "# Save the figure BEFORE showing it\n",
    "# Changed filename for the 3D version\n",
    "plt.savefig(\"merge_tsne_3d_plt_interface.pdf\", dpi=300, bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm_latest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
